{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpus:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"gpus: \", gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  (150, 4)\n",
      "y shape:  (150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "print(\"x shape: \", data.data.shape)\n",
    "print(\"y shape: \", data.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel:\n",
      "<tf.Variable 'my_dense_layer/Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[0., 5., 6.],\n",
      "       [6., 7., 1.]], dtype=float32)>\n",
      "\n",
      "bias\n",
      "<tf.Variable 'my_dense_layer/Variable:0' shape=(3,) dtype=float32, numpy=array([0., 1., 0.], dtype=float32)>\n",
      "\n",
      "trainable_variables\n",
      "[<tf.Variable 'my_dense_layer/Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[0., 5., 6.],\n",
      "       [6., 7., 1.]], dtype=float32)>, <tf.Variable 'my_dense_layer/Variable:0' shape=(3,) dtype=float32, numpy=array([0., 1., 0.], dtype=float32)>]\n",
      "\n",
      "trainable_weights\n",
      "[<tf.Variable 'my_dense_layer/Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[0., 5., 6.],\n",
      "       [6., 7., 1.]], dtype=float32)>, <tf.Variable 'my_dense_layer/Variable:0' shape=(3,) dtype=float32, numpy=array([0., 1., 0.], dtype=float32)>]\n",
      "\n",
      "config\n",
      "{'name': 'my_dense_layer', 'trainable': True, 'dtype': 'float32', 'units': 5, 'activation': 'relu'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs, activation=None, name='my_dense_layer', **kwargs):\n",
    "        super(MyDenseLayer, self).__init__(name=name, **kwargs)\n",
    "        self.num_outputs = num_outputs\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    # creating variables in build enable late variable creation\n",
    "    # based on the shape of inputs the layer will operate on.\n",
    "    def build(self, input_shape):\n",
    "        #w_init = tf.random_normal_initializer()\n",
    "        self.kernel = tf.Variable(initial_value=( np.random.randint(10, size=(input_shape[-1], self.num_outputs)) ),\n",
    "                                  trainable=True, dtype='float32')\n",
    "        #b_init = tf.zeros_initializer()\n",
    "        self.bias = tf.Variable(initial_value=( np.random.randint(10, size=(self.num_outputs)) ),\n",
    "                                trainable=True, dtype='float32')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        wx = tf.tensordot(inputs, self.kernel, [[-1], [0]])\n",
    "        b = self.bias\n",
    "        return  self.activation(wx + b)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MyDenseLayer, self).get_config()\n",
    "        config.update({'units': self.num_outputs, \n",
    "                       'activation':tf.keras.activations.serialize(self.activation)})\n",
    "        return config\n",
    "# Invoke __init__    \n",
    "my_layer = MyDenseLayer(3, activation='relu')\n",
    "\n",
    "# Invoke build() and call()\n",
    "my_layer(np.array([[1.0,2.0]]))\n",
    "\n",
    "print(\"kernel:\")\n",
    "print(my_layer.variables[0])\n",
    "print(\"\")\n",
    "\n",
    "print(\"bias\")\n",
    "print(my_layer.variables[1])\n",
    "print(\"\")\n",
    "\n",
    "print(\"trainable_variables\")\n",
    "print(my_layer.trainable_variables)\n",
    "print(\"\")\n",
    "\n",
    "# trainable_weights is the same as trainable_variables\n",
    "print(\"trainable_weights\")\n",
    "print(my_layer.trainable_weights)\n",
    "print(\"\")\n",
    "\n",
    "layer = MyDenseLayer(5, activation='relu')\n",
    "layer_config = layer.get_config()\n",
    "print(\"config\")\n",
    "print(layer_config)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradients_b_a\n",
      "tf.Tensor(\n",
      "[[5.]\n",
      " [7.]\n",
      " [9.]], shape=(3, 1), dtype=float32)\n",
      "\n",
      "gradients_c_b\n",
      "tf.Tensor(\n",
      "[[7.]\n",
      " [8.]], shape=(2, 1), dtype=float32)\n",
      "\n",
      "gradients_c_a\n",
      "tf.Tensor(\n",
      "[[39.]\n",
      " [54.]\n",
      " [69.]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(initial_value=( np.random.randint(10, size=(3,1)) ),\n",
    "                                  trainable=True, dtype='float32')\n",
    "m = tf.constant([[1.,2.,3.], [4.,5.,6.]])\n",
    "n = tf.constant([[7., 8.]])\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    b = tf.matmul(m, a)\n",
    "    c = tf.matmul(n, b)\n",
    "gradients_b_a = tape.gradient(b, a)\n",
    "gradients_c_b = tape.gradient(c, b)\n",
    "gradients_c_a = tape.gradient(c, a)\n",
    "print(\"gradients_b_a\")\n",
    "print(gradients_b_a)\n",
    "print(\"\")\n",
    "# gradient returns a sum of Jacobian matrix along\n",
    "# b-axis, rather than return a Jacobian matrix.\n",
    "# gradinet is designed to sum all gradients for \n",
    "# each sample in a batch, so it makes sense.\n",
    "\n",
    "print(\"gradients_c_b\")\n",
    "print(gradients_c_b)\n",
    "print(\"\")\n",
    "\n",
    "print(\"gradients_c_a\")\n",
    "print(gradients_c_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyModel, self).__init__(**kwargs)\n",
    "        #self.in_shape = in_shape\n",
    "        #self.input_layer = tf.keras.Input(in_shape)\n",
    "        self.d1 = MyDenseLayer(3, activation=tf.nn.relu)\n",
    "        self.d2 = MyDenseLayer(3, activation=tf.nn.softmax)\n",
    "        #elf.out = self.call(self.input_layer)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        return x\n",
    "\n",
    "    #def get_config(self):\n",
    "    #    config = super(MyModel, self).get_config()\n",
    "    ##    config.update({\"in_shape\":self.in_shape})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_ds size:  120\n",
      "te_ds size:  30\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def normalize(x, y):\n",
    "    mean = tf.math.reduce_mean(x, axis=0)\n",
    "    std = tf.math.reduce_std(x, axis=0)\n",
    "    x = (x - mean) / std\n",
    "    return x, y\n",
    "dataset = tf.data.Dataset.from_tensor_slices( (data.data, data.target) )\n",
    "### Every time we iterate through the whole dataset, do not reshuffle the dataset\n",
    "dataset = dataset.shuffle(len(dataset), seed=100, reshuffle_each_iteration=False)\n",
    "dataset = dataset.map(lambda a, b: normalize(a, b))\n",
    "\n",
    "### SparseCategorical does not need one-hot-encoding for y labels\n",
    "#dataset = dataset.map( lambda a, b: (a, tf.one_hot(b, 3)) )\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "#dataset = dataset.shuffle(len(dataset))\n",
    "tr_ds = dataset.take(train_size)\n",
    "te_ds = dataset.skip(train_size)\n",
    "print(\"tr_ds size: \", len(tr_ds))\n",
    "print(\"te_ds size: \", len(te_ds))\n",
    "tr_ds = tr_ds.shuffle(len(tr_ds), seed=100)\n",
    "tr_ds = tr_ds.batch(32)\n",
    "te_ds = te_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the input is not probability, from_logits=True and vice versa.\n",
    "# SparseCategorical accepts label, probability as input\n",
    "# ex: y_true = [1, 2], y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy =tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "# Use tf.function to make graphs out of your programs.\n",
    "# This will help you create performant and portable models.\n",
    "# tf.function works best with TF ops; Numpy and Python \n",
    "# are converted to constants.\n",
    "@tf.function\n",
    "def train_step(model, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x, training=True)\n",
    "        loss = loss_object(y, y_pred)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, y_pred)\n",
    "\n",
    "@tf.function\n",
    "def test_step(model, x, y):\n",
    "    y_pred = model(x, training=False)\n",
    "    loss = loss_object(y, y_pred)\n",
    "    test_loss(loss)\n",
    "    test_accuracy(y, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9517, Accuracy: 59.17,Test Loss: 0.8936, Test Accuracy: 56.67\n",
      "Epoch 2, Loss: 0.4633, Accuracy: 75.83,Test Loss: 0.3500, Test Accuracy: 86.67\n",
      "Epoch 3, Loss: 0.3365, Accuracy: 89.17,Test Loss: 0.3628, Test Accuracy: 90.00\n",
      "Epoch 4, Loss: 0.2181, Accuracy: 96.67,Test Loss: 0.5070, Test Accuracy: 86.67\n",
      "Epoch 5, Loss: 0.2155, Accuracy: 94.17,Test Loss: 0.3379, Test Accuracy: 90.00\n",
      "Epoch 6, Loss: 0.1840, Accuracy: 95.83,Test Loss: 0.3301, Test Accuracy: 90.00\n",
      "Epoch 7, Loss: 0.1628, Accuracy: 95.83,Test Loss: 0.3484, Test Accuracy: 93.33\n",
      "Epoch 8, Loss: 0.1637, Accuracy: 96.67,Test Loss: 0.3443, Test Accuracy: 93.33\n",
      "Epoch 9, Loss: 0.1362, Accuracy: 95.83,Test Loss: 0.3025, Test Accuracy: 90.00\n",
      "Epoch 10, Loss: 0.1408, Accuracy: 95.83,Test Loss: 0.3100, Test Accuracy: 90.00\n",
      "Epoch 11, Loss: 0.1365, Accuracy: 95.00,Test Loss: 0.3433, Test Accuracy: 93.33\n",
      "Epoch 12, Loss: 0.1344, Accuracy: 96.67,Test Loss: 0.2957, Test Accuracy: 90.00\n",
      "Epoch 13, Loss: 0.1164, Accuracy: 95.83,Test Loss: 0.3190, Test Accuracy: 90.00\n",
      "Epoch 14, Loss: 0.1262, Accuracy: 97.50,Test Loss: 0.3247, Test Accuracy: 93.33\n",
      "Epoch 15, Loss: 0.1116, Accuracy: 95.83,Test Loss: 0.2868, Test Accuracy: 90.00\n",
      "Epoch 16, Loss: 0.1400, Accuracy: 95.00,Test Loss: 0.3150, Test Accuracy: 90.00\n",
      "Epoch 17, Loss: 0.1234, Accuracy: 95.83,Test Loss: 0.2821, Test Accuracy: 90.00\n",
      "Epoch 18, Loss: 0.1159, Accuracy: 95.83,Test Loss: 0.3338, Test Accuracy: 93.33\n",
      "Epoch 19, Loss: 0.1231, Accuracy: 96.67,Test Loss: 0.3055, Test Accuracy: 90.00\n",
      "Epoch 20, Loss: 0.1069, Accuracy: 95.83,Test Loss: 0.2774, Test Accuracy: 90.00\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for tr_x, tr_y in tr_ds:\n",
    "        train_step(model, tr_x, tr_y)\n",
    "\n",
    "    for te_x, te_y in te_ds:\n",
    "        test_step(model, te_x, te_y)  \n",
    "\n",
    "    print(f'Epoch {epoch + 1}, ' \n",
    "          f'Loss: {train_loss.result():.4f}, '\n",
    "          f'Accuracy: {train_accuracy.result() * 100:.2f},'\n",
    "          f'Test Loss: {test_loss.result():.4f}, '\n",
    "          f'Test Accuracy: {test_accuracy.result() * 100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_dense_layer (MyDenseLaye  multiple                 15        \n",
      " r)                                                              \n",
      "                                                                 \n",
      " my_dense_layer (MyDenseLaye  multiple                 12        \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27\n",
      "Trainable params: 27\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.save_weights(\"my_checkpoint\")\n",
    "model.save(\"my_model\")\n",
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Test Loss: 0.2774, Test Accuracy: 90.00\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('my_model')\n",
    "\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "for te_x, te_y in te_ds:\n",
    "        test_step(new_model, te_x, te_y) \n",
    "        break\n",
    "\n",
    "print(f'Test Loss: {test_loss.result():.4f}, '\n",
    "      f'Test Accuracy: {test_accuracy.result() * 100:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ob_detect')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b10890bcf299a1fc22693352a5817f19050542817e769795d1b80e0243d6dd67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
