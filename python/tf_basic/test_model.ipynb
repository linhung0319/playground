{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpus:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"gpus: \", gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  (150, 4)\n",
      "y shape:  (150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "print(\"x shape: \", data.data.shape)\n",
    "print(\"y shape: \", data.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel:\n",
      "<tf.Variable 'my_dense_layer_21/Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[8., 0., 1.],\n",
      "       [2., 0., 9.]], dtype=float32)>\n",
      "\n",
      "bias\n",
      "<tf.Variable 'my_dense_layer_21/Variable:0' shape=(3,) dtype=float32, numpy=array([4., 5., 3.], dtype=float32)>\n",
      "\n",
      "trainable_variables\n",
      "[<tf.Variable 'my_dense_layer_21/Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[8., 0., 1.],\n",
      "       [2., 0., 9.]], dtype=float32)>, <tf.Variable 'my_dense_layer_21/Variable:0' shape=(3,) dtype=float32, numpy=array([4., 5., 3.], dtype=float32)>]\n",
      "\n",
      "trainable_weights\n",
      "[<tf.Variable 'my_dense_layer_21/Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[8., 0., 1.],\n",
      "       [2., 0., 9.]], dtype=float32)>, <tf.Variable 'my_dense_layer_21/Variable:0' shape=(3,) dtype=float32, numpy=array([4., 5., 3.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs, activation=lambda x: x):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        self.activation = activation\n",
    "\n",
    "    # creating variables in build enable late variable creation\n",
    "    # based on the shape of inputs the layer will operate on.\n",
    "    def build(self, input_shape):\n",
    "        #w_init = tf.random_normal_initializer()\n",
    "        self.kernel = tf.Variable(initial_value=( np.random.randint(10, size=(input_shape[-1], self.num_outputs)) ),\n",
    "                                  trainable=True, dtype='float32')\n",
    "        #b_init = tf.zeros_initializer()\n",
    "        self.bias = tf.Variable(initial_value=( np.random.randint(10, size=(self.num_outputs)) ),\n",
    "                                trainable=True, dtype='float32')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        wx = tf.tensordot(inputs, self.kernel, [[-1], [0]])\n",
    "        b = self.bias\n",
    "        return  self.activation(wx + b)\n",
    "\n",
    "# Invoke __init__    \n",
    "my_layer = MyDenseLayer(3)\n",
    "\n",
    "# Invoke build() and call()\n",
    "my_layer(np.array([[1.0,2.0]]))\n",
    "\n",
    "print(\"kernel:\")\n",
    "print(my_layer.variables[0])\n",
    "print(\"\")\n",
    "\n",
    "print(\"bias\")\n",
    "print(my_layer.variables[1])\n",
    "print(\"\")\n",
    "\n",
    "print(\"trainable_variables\")\n",
    "print(my_layer.trainable_variables)\n",
    "print(\"\")\n",
    "\n",
    "# trainable_weights is the same as trainable_variables\n",
    "print(\"trainable_weights\")\n",
    "print(my_layer.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradients_b_a\n",
      "tf.Tensor(\n",
      "[[5.]\n",
      " [7.]\n",
      " [9.]], shape=(3, 1), dtype=float32)\n",
      "\n",
      "gradients_c_b\n",
      "tf.Tensor(\n",
      "[[7.]\n",
      " [8.]], shape=(2, 1), dtype=float32)\n",
      "\n",
      "gradients_c_a\n",
      "tf.Tensor(\n",
      "[[39.]\n",
      " [54.]\n",
      " [69.]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(initial_value=( np.random.randint(10, size=(3,1)) ),\n",
    "                                  trainable=True, dtype='float32')\n",
    "m = tf.constant([[1.,2.,3.], [4.,5.,6.]])\n",
    "n = tf.constant([[7., 8.]])\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    b = tf.matmul(m, a)\n",
    "    c = tf.matmul(n, b)\n",
    "gradients_b_a = tape.gradient(b, a)\n",
    "gradients_c_b = tape.gradient(c, b)\n",
    "gradients_c_a = tape.gradient(c, a)\n",
    "print(\"gradients_b_a\")\n",
    "print(gradients_b_a)\n",
    "print(\"\")\n",
    "# gradient returns a sum of Jacobian matrix along\n",
    "# b-axis, rather than return a Jacobian matrix.\n",
    "# gradinet is designed to sum all gradients for \n",
    "# each sample in a batch, so it makes sense.\n",
    "\n",
    "print(\"gradients_c_b\")\n",
    "print(gradients_c_b)\n",
    "print(\"\")\n",
    "\n",
    "print(\"gradients_c_a\")\n",
    "print(gradients_c_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.d1 = MyDenseLayer(3, activation=tf.nn.softmax)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.d1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_ds size:  120\n",
      "te_ds size:  30\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def normalize(x, y):\n",
    "    mean = tf.math.reduce_mean(x, axis=0)\n",
    "    std = tf.math.reduce_std(x, axis=0)\n",
    "    x = (x - mean) / std\n",
    "    return x, y\n",
    "dataset = tf.data.Dataset.from_tensor_slices( (data.data, data.target) )\n",
    "dataset = dataset.shuffle(len(dataset), seed=100)\n",
    "dataset = dataset.map(lambda a, b: normalize(a, b))\n",
    "\n",
    "### SparseCategorical does not need one-hot-encoding for y labels\n",
    "#dataset = dataset.map( lambda a, b: (a, tf.one_hot(b, 3)) )\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "dataset = dataset.shuffle(len(dataset))\n",
    "tr_ds = dataset.take(train_size)\n",
    "te_ds = dataset.skip(train_size)\n",
    "print(\"tr_ds size: \", len(tr_ds))\n",
    "print(\"te_ds size: \", len(te_ds))\n",
    "tr_ds = tr_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the input is not probability, from_logits=True and vice versa.\n",
    "# SparseCategorical accepts label, probability as input\n",
    "# ex: y_true = [1, 2], y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy =tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "# Use tf.function to make graphs out of your programs.\n",
    "# This will help you create performant and portable models.\n",
    "# tf.function works best with TF ops; Numpy and Python \n",
    "# are converted to constants.\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x, training=True)\n",
    "        loss = loss_object(y, y_pred)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(y, y_pred)\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    y_pred = model(x, training=False)\n",
    "    loss = loss_object(y, y_pred)\n",
    "    test_loss(loss)\n",
    "    test_accuracy(y, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4338, Accuracy: 77.50,Test Loss: 0.4105, Test Accuracy: 73.33\n",
      "Epoch 2, Loss: 0.4019, Accuracy: 77.50,Test Loss: 0.3351, Test Accuracy: 90.00\n",
      "Epoch 3, Loss: 0.3418, Accuracy: 87.50,Test Loss: 0.3460, Test Accuracy: 86.67\n",
      "Epoch 4, Loss: 0.3340, Accuracy: 87.50,Test Loss: 0.2173, Test Accuracy: 100.00\n",
      "Epoch 5, Loss: 0.3024, Accuracy: 88.33,Test Loss: 0.3291, Test Accuracy: 86.67\n",
      "Epoch 6, Loss: 0.2716, Accuracy: 90.00,Test Loss: 0.3601, Test Accuracy: 83.33\n",
      "Epoch 7, Loss: 0.2678, Accuracy: 90.83,Test Loss: 0.2582, Test Accuracy: 90.00\n",
      "Epoch 8, Loss: 0.2558, Accuracy: 90.83,Test Loss: 0.2426, Test Accuracy: 90.00\n",
      "Epoch 9, Loss: 0.2181, Accuracy: 93.33,Test Loss: 0.1753, Test Accuracy: 96.67\n",
      "Epoch 10, Loss: 0.2220, Accuracy: 92.50,Test Loss: 0.2597, Test Accuracy: 86.67\n",
      "Epoch 11, Loss: 0.2228, Accuracy: 92.50,Test Loss: 0.4323, Test Accuracy: 80.00\n",
      "Epoch 12, Loss: 0.2048, Accuracy: 94.17,Test Loss: 0.2515, Test Accuracy: 90.00\n",
      "Epoch 13, Loss: 0.1842, Accuracy: 93.33,Test Loss: 0.1219, Test Accuracy: 96.67\n",
      "Epoch 14, Loss: 0.2106, Accuracy: 90.83,Test Loss: 0.1597, Test Accuracy: 96.67\n",
      "Epoch 15, Loss: 0.1858, Accuracy: 95.83,Test Loss: 0.1270, Test Accuracy: 100.00\n",
      "Epoch 16, Loss: 0.2087, Accuracy: 92.50,Test Loss: 0.1260, Test Accuracy: 100.00\n",
      "Epoch 17, Loss: 0.2022, Accuracy: 92.50,Test Loss: 0.1148, Test Accuracy: 96.67\n",
      "Epoch 18, Loss: 0.1726, Accuracy: 93.33,Test Loss: 0.2128, Test Accuracy: 93.33\n",
      "Epoch 19, Loss: 0.1817, Accuracy: 92.50,Test Loss: 0.1901, Test Accuracy: 90.00\n",
      "Epoch 20, Loss: 0.1670, Accuracy: 92.50,Test Loss: 0.1296, Test Accuracy: 93.33\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for tr_x, tr_y in tr_ds:\n",
    "        train_step(tr_x, tr_y)\n",
    "\n",
    "    for te_x, te_y in te_ds:\n",
    "        test_step(te_x, te_y)  \n",
    "\n",
    "    print(f'Epoch {epoch + 1}, ' \n",
    "          f'Loss: {train_loss.result():.4f}, '\n",
    "          f'Accuracy: {train_accuracy.result() * 100:.2f},'\n",
    "          f'Test Loss: {test_loss.result():.4f}, '\n",
    "          f'Test Accuracy: {test_accuracy.result() * 100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_dense_layer_22 (MyDenseL  multiple                 15        \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.save_weights(\"my_checkpoint\")\n",
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Test Loss: 0.1699, Test Accuracy: 93.33\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('my_model')\n",
    "\n",
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "for te_x, te_y in te_ds:\n",
    "        test_step(te_x, te_y) \n",
    "\n",
    "print(f'Test Loss: {test_loss.result():.4f}, '\n",
    "      f'Test Accuracy: {test_accuracy.result() * 100:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ob_detect')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b10890bcf299a1fc22693352a5817f19050542817e769795d1b80e0243d6dd67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
